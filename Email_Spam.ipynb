{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data from spambase.data file, downloaded from UCI data set website. Print out first 6 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
      "0            0.00               0.64           0.64           0.0   \n",
      "1            0.21               0.28           0.50           0.0   \n",
      "2            0.06               0.00           0.71           0.0   \n",
      "3            0.00               0.00           0.00           0.0   \n",
      "4            0.00               0.00           0.00           0.0   \n",
      "5            0.00               0.00           0.00           0.0   \n",
      "\n",
      "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
      "0           0.32            0.00              0.00                0.00   \n",
      "1           0.14            0.28              0.21                0.07   \n",
      "2           1.23            0.19              0.19                0.12   \n",
      "3           0.63            0.00              0.31                0.63   \n",
      "4           0.63            0.00              0.31                0.63   \n",
      "5           1.85            0.00              0.00                1.85   \n",
      "\n",
      "   word_freq_order  word_freq_mail  ...   char_freq_;  char_freq_(  \\\n",
      "0             0.00            0.00  ...          0.00        0.000   \n",
      "1             0.00            0.94  ...          0.00        0.132   \n",
      "2             0.64            0.25  ...          0.01        0.143   \n",
      "3             0.31            0.63  ...          0.00        0.137   \n",
      "4             0.31            0.63  ...          0.00        0.135   \n",
      "5             0.00            0.00  ...          0.00        0.223   \n",
      "\n",
      "   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n",
      "0          0.0        0.778        0.000        0.000   \n",
      "1          0.0        0.372        0.180        0.048   \n",
      "2          0.0        0.276        0.184        0.010   \n",
      "3          0.0        0.137        0.000        0.000   \n",
      "4          0.0        0.135        0.000        0.000   \n",
      "5          0.0        0.000        0.000        0.000   \n",
      "\n",
      "   capital_run_length_average  capital_run_length_longest  \\\n",
      "0                       3.756                          61   \n",
      "1                       5.114                         101   \n",
      "2                       9.821                         485   \n",
      "3                       3.537                          40   \n",
      "4                       3.537                          40   \n",
      "5                       3.000                          15   \n",
      "\n",
      "   capital_run_length_total  spam  \n",
      "0                       278     1  \n",
      "1                      1028     1  \n",
      "2                      2259     1  \n",
      "3                       191     1  \n",
      "4                       191     1  \n",
      "5                        54     1  \n",
      "\n",
      "[6 rows x 58 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4601, 58)"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spambase.data', sep = ',', header = None)\n",
    "df.columns = [\"word_freq_make\", \"word_freq_address\", \"word_freq_all\", \"word_freq_3d\", \"word_freq_our\", \"word_freq_over\", \"word_freq_remove\", \"word_freq_internet\", \"word_freq_order\", \"word_freq_mail\", \"word_freq_receive\", \"word_freq_will\", \"word_freq_people\", \"word_freq_report\", \"word_freq_addresses\", \"word_freq_free\", \"word_freq_business\", \"word_freq_email\", \"word_freq_you\", \"word_freq_credit\", \"word_freq_your\", \"word_freq_font\", \"word_freq_000\", \"word_freq_money\", \"word_freq_hp\", \"word_freq_hpl\", \"word_freq_george\", \"word_freq_650\", \"word_freq_lab\", \"word_freq_labs\", \"word_freq_telnet\", \"word_freq_857\", \"word_freq_data\", \"word_freq_415\", \"word_freq_85\", \"word_freq_technology\", \"word_freq_1999\", \"word_freq_parts\", \"word_freq_pm\", \"word_freq_direct\", \"word_freq_cs\", \"word_freq_meeting\", \"word_freq_original\", \"word_freq_project\", \"word_freq_re\", \"word_freq_edu\", \"word_freq_table\", \"word_freq_conference\", \"char_freq_;\", \"char_freq_(\", \"char_freq_[\", \"char_freq_!\", \"char_freq_$\", \"char_freq_#\", \"capital_run_length_average\", \"capital_run_length_longest\", \"capital_run_length_total\", \"spam\"]\n",
    "print(df.head(6))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Using classic Naive Bayes Spam Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Multinomial model naive bayes spam filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide data into two parts, 3500 train data and 1101 test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(df.iloc[0:,:58])\n",
    "np.random.shuffle(data)\n",
    "nTrain = 3500\n",
    "nTest = 1101\n",
    "dataTrain = data[0:nTrain, :]\n",
    "dataTest = data[nTrain+1:nTrain+nTest, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For naive bayes spam filter, it only uses the frequency of each word shown up in the email content. So we only use first 54 columns as our Xtrain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = dataTrain[:, 0:54]\n",
    "ytrain = dataTrain[:, 57]\n",
    "Xtest = dataTest[:, 0:54]\n",
    "ytest = dataTest[:, 57]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit in the data and predict it by Xtest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(Xtrain, ytrain)\n",
    "ypredicted = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the accuracy of prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88090909090909086"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acci = np.mean(ypredicted == ytest)\n",
    "acci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the output(spam for 1, not spam for 0) is incontinous, we use logistic regression model to find the relationship between input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS for training is 0.284426 and RSS for testing is 0.362212\n",
      "Accuracy on training data = 0.911818\n"
     ]
    }
   ],
   "source": [
    "Xtrain = dataTrain[:, 0:57]\n",
    "Xtest = dataTest[:, 0:57]\n",
    "regr = linear_model.LogisticRegression(C=77)\n",
    "regr.fit(Xtrain, ytrain)\n",
    "ypred = regr.predict(Xtrain)\n",
    "RSStr = np.mean(((ypred-ytrain)**2)/(np.std(ytrain)**2))\n",
    "ytestpred = regr.predict(Xtest)\n",
    "RSSte = np.mean(((ytestpred-ytest)**2)/(np.std(ytest)**2))\n",
    "print(\"RSS for training is %f and RSS for testing is %f\"%(RSStr,RSSte))\n",
    "acc = np.mean(ytestpred == ytest)\n",
    "print(\"Accuracy on training data = %f\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After logistic regression using a random parameter C=77,we get RSS which looks a little bit large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13b3e6eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m=np.squeeze(regr.coef_)\n",
    "plt.stem(m)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stem diagram shows that there are almost all coeffients that have a influence on the output. Therefore, next we will get rid of the coeffients that nearly have no influence on the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Using Ligistic model with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test data is  =  0.9276\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "nfold = 10\n",
    "kf = KFold(n_splits=nfold,shuffle=True)\n",
    "err_rate=np.zeros(nfold)\n",
    "x = data[:,0:57]\n",
    "y=data[:,57]\n",
    "for ifold, Ind in enumerate(kf.split(x)):   \n",
    "    Itr,Its=Ind\n",
    "    Xtr = x[Itr,:]\n",
    "    ytr = y[Itr]\n",
    "    Xts = x[Its,:]\n",
    "    yts = y[Its]\n",
    "    regr.fit(Xtr, ytr)\n",
    "    yhat = regr.predict(Xts)\n",
    "    err_rate[ifold]=np.mean(yhat!=yts)\n",
    "error_mean=np.mean(err_rate)\n",
    "error_se=np.std(err_rate)/np.sqrt(nfold-1)\n",
    "print('Accuracy on the test data is  =  {0:.4f}'.format(1-error_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is obvious that the error rate decreases dramatically after 10 kfold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGcFJREFUeJzt3X2MHPd93/HPh8cTc5EUn2XSsnjSmTJKEFDqmNccZLtS\nW1uRRZkxQkZNY+XBtVMYdAq5cIqYjhgDjRvAEFs2Dy3sWmYdIQ7iyHZrkhJs1aweHDg2qgdSR4t6\nIsxSsqQjI5JWTrKkAx+O3/6xe/TO3czePs3uzO77BRxud2Zu7vfbnZ3Pb37zm1lHhAAAmLes1wUA\nABQLwQAASCAYAAAJBAMAIIFgAAAkEAwAgASCAQCQQDAAABIIBgBAwvJeF6AVK1eujDVr1vS6GABQ\nKvv37z8ZEauWWq6UwbBmzRrt27ev18UAgFKx/aNGlqMrCQCQQDAAABIIBgBAAsEAAEggGAAACaUc\nlQQARbVnalo79h7S0ZlZrR4d0dYN67R5YqzXxWoKwQAAHbJnalrbdh3U7Jk5SdL0zKy27TooSaUK\nB7qSAKBDduw9dD4U5s2emdOOvYd6VKLWEAwA0CFHZ2abml5UuQeD7WdtH7R9wPaiy5Vd8d9sH7b9\nmO1/kneZACAPq0dHmppeVN06YnhvRKyPiMmUee+XtLb6s0XSF7pUJgDoqK0b1mlkeCgxbWR4SFs3\nrOtRiVpThK6kTZL+KioelDRq+7JeFwoAmrV5Yky33fR2XTBU2bWOjY7otpveXqoTz1J3RiWFpPts\nz0n6YkTsXDB/TNLzNc9fqE47VruQ7S2qHFFofHw8v9ICQBs2T4zpzoefkyR97WPv7nFpWtONI4Zr\nI2K9Kl1Gt9j+562sJCJ2RsRkREyuWrXkXWMBAC3KPRgiYrr6+7ik3ZKuXrDItKQrap5fXp0GAOiB\nXIPB9oW2L55/LOkGSY8vWOxuSf+6OjrpXZJejohjAgD0RN7nGC6VtNv2/P/6m4j4tu3flaSIuF3S\nPZI2Sjos6XVJv5NzmQAAdeQaDBFxRNI7UqbfXvM4JN2SZzkAAI0rwnBVAECBEAwAgASCAQCQQDAA\nABIIBgBAAsEAAEggGAAACQQDACCBYAAAJBAMAIAEggEAkEAwAAASCAYAQALBAABIIBgAAAkEAwAg\ngWAAACQQDACABIIBAJBAMAAAEnINBttX2P6O7SdtP2H7EynLvMf2y7YPVH/+Q55lAgDUtzzn9Z+V\n9PsR8ajtiyXtt31vRDy5YLm/i4gP5FwWAEADcj1iiIhjEfFo9fFPJD0laSzP/wkAaE/eRwzn2V4j\naULSQymz/6ntxyRNS/pkRDzRrXJ1056pae3Ye0hHZ2a1enREWzes0+YJchJAsXQlGGxfJOkbkn4v\nIl5ZMPtRSeMR8artjZL2SFqbso4tkrZI0vj4eM4lXqzdnfqeqWlt23VQs2fmJEnTM7PatuugJBEO\nHUDoosjKtn3mPirJ9rAqofCViNi1cH5EvBIRr1Yf3yNp2PbKlOV2RsRkREyuWrUq72InzO/Up2dm\nFfrpTn3P1HTD69ix99D5UJg3e2ZOO/Ye6nBpB08n3h8gL2XcPvMelWRJfyHpqYj404xl3lJdTrav\nrpbpx3mWq1md2KkfnZltajoaR+iiyMq4febdlXSNpA9JOmj7QHXaH0oal6SIuF3Sr0n6t7bPSpqV\ndHNERM7lakonduqrR0c0nbL86tGRlsuFCkIXRVbG7TPXYIiI70nyEst8TtLn8ixHuzqxU9+6YV3i\nHIMkjQwPaeuGdR0p4yAjdFFkZdw+ufK5AVs3rNPI8FBiWrM79c0TY7rtprfrgqHKSz42OqLbbnp7\noU9AlUUn3p8i2DM1rWu2P6Arb/2Wrtn+QKH7oNG4Mm6fXRuuWmbzO+9P/a/HdHrunMZaHFWweWJM\ndz78nCTpax97d8fLOag69f70EqPW+lcZt0+CoUHs1Iut7O9PvROURd6BoDFl2z7pSgIKoIwnKNG/\nCAagALJORBb5BCX6F8EAFEAZT1Cif3GOAanKdgl/2ZXxBCX6F8GARRgh0xtlO0GJ/kVXEhYp4yX8\nADqHIwYsUm+ETB5dTHRbAcVCMGCRrEv43zAynNrFtO9HL+k7T59oacdOt1W+CF20gq6kHJT91gZZ\nI2RspXYxfeXB51q+pTDdVvkp4+2eUQwEQ4d16sPYy3DJuq/TzOtnUpdfeCvcZnbsXNjVmka2D0IX\nrSIYOqwTH8YitPQ2T4xpYnxU77zyEn3/1uu0eWKsqYutGt2xc2FX8xrdPghdtIpgaNPCllta37yU\n/WFMa/kVtaWX1sWUdU/1RnfsXNjVvEa3D0IXrSIY2pDWcmtmR5nV8ms2XLolrYvpt9413taOvYy3\nI+/1OaRGjwQIXbSKUUltSGu5hSqt6Np+96wPY1bLb8jWXMqX2BWhpZd2EdbkWy9p64rdvC7symto\nba9HUTX6xS9cTY1WEQxtyGq5haQLhpYt+WHM+vu5CI0MD5Xm296KeMVuXjvwItweu5lvAyzie9Mv\n+nkoMMHQhqyW29joiC5/Y6X1Vu/DWO/vt25YN/AtvbQPnqSGPox57cCLcEKXI4HeK8KRY54IhhSN\ntgTqtdzmW2n11Pv7tJZeXi2UIrZ80j54W//nDyRLZ+bi/LSsD2NeO/CifH8vRwK9VYQjxzzlHgy2\nb5T0XyUNSfpSRGxfMN/V+RslvS7pIxHxaN7lylKvJbBQvZZbI8HQTMsvrxZKM/VtZd2dbPGfObf4\nvEvWhzGvHXgz3ThFVsTGQJkU4cgxT7kGg+0hSZ+X9D5JL0h6xPbdEfFkzWLvl7S2+vNOSV+o/u6J\nei2B+e6hWu223Br9+7xaKM3Wt1HNtvgXauYDlrZsXjvwTnTj9Hqn3O/dIN3QqYZHM42nbm43eR8x\nXC3pcEQckSTbX5W0SVJtMGyS9FcREZIetD1q+7KIOJZz2SQtfmPqDRVtZ0fZrmZbKI1ucPXW2059\nm23xL/xf9d6LhdI+jHn2w7fTGCjCTrnfu0G6oRMNj2YaT/t+9JK+sX+6a9uNI2VYZMdWbv+apBsj\n4qPV5x+S9M6I+HjNMt+UtD0ivld9fr+kP4iIfVnrnZycjH37Mmdnuuujn9To0We05k0XSpJOvnpK\nR06+pnMpO6yFViwf0orhylj7qy77ucS8J4+9smh62rR2lp16bkanziY/zPPlmhgf1bM/fk2StOZN\nF6bWq9JjJ9W+38uWWctsnZ071/H6Pnjkx4vWWc/PjQwn/r6ZOrxt5YVaedGKpl7b2ter2WlZ681a\ntnb6Uu9jM+ttdNlm3pu3vOFnlqzDUuVq97Xt5bInXz2lZ06+prlzoRXLh3TFJSNaedGKzGX/34nX\nFLF42Ua2xaxtIY3t89v9kTeM6Yu/sElSZaDK92+9rqF1VNezPyIml1quNCefbW+RtEWSxsfHW1rH\nS6+d0gWnf/pGPP/SbEOhsGyZdcUlI3r11NnU+T97wVBD09pZ9opLRhbtKOfLdfLVU3rxlVOKCP3D\na2c0F7GoXmkNgHPnQsuGrGXLnLreduq7YvlQwxv9iuVDi/5+/gO28EOaNm1+2WZe29dPLy5bo9Oy\n1pu1bO30rNdkfnoz62102UbfmxXLhxqqg6RF21zt+9Dua9urZRc2Rk6dndORk5UwWHnRikV/v/Ki\nFec/IwtDqJFtsdHPh5T++ZXyO6eR9xHDuyV9JiI2VJ9vk6SIuK1mmS9K+tuIuLP6/JCk99TrSmrl\niGHP1PSiboV//7UDi24AN29sdKRwJ+ayuocWHtI2w5L+7IPrc78QTJKGlzlxmCxVDr97caXzB7/4\nfyUlu4IandbMOhdud6+fPqt/SLkZYb2WX7tlWCjtvZl/H7K6yGrXW+/vN0+Mtf3a9mrZrFvazL83\nzbwPjah3C52Fsi56LesRwyOS1tq+UtK0pJsl/eaCZe6W9PHq+Yd3Snq50+cX5jfk09Uuk/n+udGf\nHW76Q9pLmyfGFu1Ar9n+QMuhIFX659PW26759bU6KqkfpG13w8us4SEvCsdujmrKem8aHU3Xr+co\nuj3SKO08RVbj6V/+4ljiHMP89Ly2m1yDISLO2v64pL2qDFe9IyKesP271fm3S7pHlaGqh1UZrvo7\nnS5H1oa8YvmyUl1hnKbRjTZrg8uzrlmBU+adRzOyTsCPjgzrwhXLexqO7TQG+nWoZrevUWm28TT5\n1kv6ZlSSIuIeVXb+tdNur3kckm7JswxZG+zLs2dy6UbppqyNOW3nIw1Oa70I6m13B/7ohi6XZml7\npqY19dyMTs+d0zXbH8jcPopykV+n1Rtp1Ohr06xmGk95HNlnKc3J53bU25C7+WLnIWtj/syv/PxA\nt9aLoEw70KzuVmnxNtMvF/ktVK8F3+hr0y8G4rbb/Xz74fnbVo+Njsgqx22rB0Untrv5lupDz7yU\n6y2+m/kOkG5vc916DaRK3b5/63V6Zvsvn/+CqqJ+P0qeBuKIod7Jtn5Q9qOeftXudtdMK75d9c4b\nZHWjdGOb6+ZrkKVfz6nUMxDBILHzRG+0s911c/RPVrfXG0aGe7pjLsIIqDJ1CXbKQHQlAUvpZndF\no7rZUs3q9rLV026UIrTW+7krOgvBgIGX1V3R63Do5nc2Z503mEm5zkfq3o65CN9bPYjn8QamKwnI\nktcdZtvV7dE/ad1eO/YeyqUbpdHhn0UZATVoXdEcMWDgFaG7Ik0RWqp5dKM0c4SW52tQxO7DouCI\nAQOvyCcXe91SzWNEX7MnlPN4DYow2qnIOGLAwBvEk4vNSBvb345GhsY20opvp8U/iNcmNINgwMAr\nQpfNIMk6EssaGpu2w293wEBRuw+Lgq4kQL3vshkkWSeU6w2NTTsp3s6AgSJ3HxYBRwwAuqoTQ2Pb\nbfHTfVgfRwwAuq7dobHttvj7/TY57eKIAQOHYYrF1EwrvhMt/k6fVO8nBAMGSlGvckZzgwAYMJAv\nupIwUIpwUzZka2YQAAMG8sMRAwZKPw9TpIsMnUIwYKAU4aZseaCLrIJw7AyCAQMlr2GKvd4hcSUv\n4dhJuQWD7R22n7b9mO3dtkczlnvW9kHbB2zvy6s8gJTPScsi7JD6uYusUYRj5+R58vleSdsi4qzt\n/yRpm6Q/yFj2vRFxMseyAOd1+qRlEU5ocyUv4dhJuR0xRMT/iYiz1acPSro8r/8F9FIRdkhFvpK3\nW91s/Xr+qBe6dY7h30j63xnzQtJ9tvfb3tKl8gAdU4QdUlHH9Xezm63I4Vg2bXUl2b5P0ltSZn06\nIu6qLvNpSWclfSVjNddGxLTtN0u61/bTEfHdlP+1RdIWSRofH2+n2EBH8S1j2brZzcZtLjqnrWCI\niOvrzbf9EUkfkPRLEREZ65iu/j5ue7ekqyUtCoaI2ClppyRNTk6mrgvoBXZI2brdzVbEcCyj3E4+\n275R0qck/YuIeD1jmQslLYuIn1Qf3yDpj/MqE5AXdkjpOCleTnmeY/icpItV6R46YPt2SbK92vY9\n1WUulfQ92z+Q9LCkb0XEt3MsE4Auot+/nHI7YoiIf5Qx/aikjdXHRyS9I68yAOgtutnKiZvoAcgV\n3Wzlwy0xAAAJBAMAIIFgAAAkEAwAgASCAQCQQDAAABIIBgBAAsEAAEggGAAACQQDACCBYADQ97r1\nLXL9gmAA0Ne6+S1y/YJgANDX6n2LHNIRDAD6Wre/Ra4fEAwA+lrWt8XxLXLZCAYAfY1vkWseX9QD\noK/xLXLNIxgA9D2+Ra45dCUBABJyCwbbn7E9bftA9WdjxnI32j5k+7DtW/MqDwCgMXl3Jf1ZRPyX\nrJm2hyR9XtL7JL0g6RHbd0fEkzmXCwCQodddSVdLOhwRRyLitKSvStrU4zIBwEDLOxj+ne3HbN9h\n+40p88ckPV/z/IXqNABAj7QVDLbvs/14ys8mSV+Q9DZJ6yUdk/Qnbf6vLbb32d534sSJdlYFAKij\nrXMMEXF9I8vZ/h+Svpkya1rSFTXPL69OS/tfOyXtlKTJyclorqQAgEblOSrpspqnvyrp8ZTFHpG0\n1vaVti+QdLOku/MqEwBgaXmOSvrPttdLCknPSvqYJNleLelLEbExIs7a/rikvZKGJN0REU/kWCYA\nwBJyC4aI+FDG9KOSNtY8v0fSPXmVAwDQnF4PVwUAFAzBAABIIBgAAAkEAwAggWAAACQQDACABIIB\nAJBAMAAAEggGAEACwQAASCAYAAAJBAMAIIFgAAAkEAwAgASCAQCQQDAAABIIBgBAAsEAAEggGAAA\nCQQDACBheV4rtv01SeuqT0clzUTE+pTlnpX0E0lzks5GxGReZQIALC23YIiID84/tv0nkl6us/h7\nI+JkXmUBADQut2CYZ9uSfl3SdXn/LwBA+7pxjuGfSXoxIn6YMT8k3Wd7v+0tXSgPAKCOto4YbN8n\n6S0psz4dEXdVH/+GpDvrrObaiJi2/WZJ99p+OiK+m/K/tkjaIknj4+PtFBsAUEdbwRAR19ebb3u5\npJsk/WKddUxXfx+3vVvS1ZIWBUNE7JS0U5ImJyejjWIDAOrIuyvpeklPR8QLaTNtX2j74vnHkm6Q\n9HjOZQIA1JF3MNysBd1Itlfbvqf69FJJ37P9A0kPS/pWRHw75zIBAOrIdVRSRHwkZdpRSRurj49I\nekeeZQAANIcrnwEACQQDACCBYAAAJBAMAIAEggEAkEAwAOiYPVPTmnpuRg8985Ku2f6A9kxN97pI\naAHBAKAj9kxNa9uugzo9d06SND0zq227DhIOJUQwAOiIHXsPafbMXGLa7Jk57dh7qEclQqsIBgAd\ncXRmtqnpKC6CAUBHrB4daWo6iotgANARWzes08jwUGLayPCQtm5Yl/EXKKrcv8ENwGDYPDEmqXKu\n4ejMrFaPjmjrhnXnp6M8CAYAHbN5Yowg6AN0JQEAEggGAEACwQAASCAYAAAJBAMAIIFgAAAkEAwA\ngASCAQCQ0FYw2P5Xtp+wfc725IJ522wftn3I9oaMv7/E9r22f1j9/cZ2ygMAaF+7RwyPS7pJ0ndr\nJ9q+StLNkn5e0o2S/rvtocV/rlsl3R8RayXdX30OAOihtoIhIp6KiLSbrW+S9NWIOBURz0g6LOnq\njOW+XH38ZUmb2ykPAKB9eZ1jGJP0fM3zF6rTFro0Io5VH/+9pEuzVmh7i+19tvedOHGicyUFACQs\nGQy277P9eMrPpk4WJCJCUtSZvzMiJiNictWqVZ381wCAGkveXTUirm9hvdOSrqh5fnl12kIv2r4s\nIo7ZvkzS8Rb+FwCgg/LqSrpb0s22V9i+UtJaSQ9nLPfh6uMPS7orp/IAABrU7nDVX7X9gqR3S/qW\n7b2SFBFPSPq6pCclfVvSLRExV/2bL9UMbd0u6X22fyjp+upzAEAPtfVFPRGxW9LujHmflfTZlOkf\nrXn8Y0m/1E4ZAACdxZXPAIAEggEAkEAwAAASCAYAQALBAABIIBgAAAkEAwAggWAAACQQDACABIIB\nAJBAMAAZ9kxNa+q5GT30zEu6ZvsD2jOVdoNgoP8QDECKPVPT2rbroE7PnZMkTc/Matuug4QDBgLB\nAKTYsfeQZs/MJabNnpnTjr1p32QL9BeCAUhxdGa2qelAPyEYgBSrR0eamg70E4IBSLF1wzqNDA8l\npo0MD2nrhnU9KhHQPW19UQ/QrzZPjEmqnGs4OjOr1aMj2rph3fnpQD8jGIAMmyfGCAIMJLqSAAAJ\nBAMAIIFgAAAkEAwAgASCAQCQ4IjodRmaZvuEpB+1+OcrJZ3sYHGKpF/rRr3Kp1/rVvZ6vTUiVi21\nUCmDoR2290XEZK/LkYd+rRv1Kp9+rVu/1mshupIAAAkEAwAgYRCDYWevC5Cjfq0b9Sqffq1bv9Yr\nYeDOMQAA6hvEIwYAQB0DFQy2b7R9yPZh27f2ujytsn2H7eO2H6+Zdonte23/sPr7jb0sYytsX2H7\nO7aftP2E7U9Up/dD3X7G9sO2f1Ct23+sTi993STJ9pDtKdvfrD4vfb1sP2v7oO0DtvdVp5W+Xo0Y\nmGCwPSTp85LeL+kqSb9h+6relqplfynpxgXTbpV0f0SslXR/9XnZnJX0+xFxlaR3Sbql+h71Q91O\nSbouIt4hab2kG22/S/1RN0n6hKSnap73S73eGxHra4ao9ku96hqYYJB0taTDEXEkIk5L+qqkTT0u\nU0si4ruSXloweZOkL1cff1nS5q4WqgMi4lhEPFp9/BNVdjRj6o+6RUS8Wn06XP0J9UHdbF8u6Zcl\nfalmcunrlaFf65UwSMEwJun5mucvVKf1i0sj4lj18d9LurSXhWmX7TWSJiQ9pD6pW7W75YCk45Lu\njYh+qdufS/qUpHM10/qhXiHpPtv7bW+pTuuHei2JL+rpQxERtks73Mz2RZK+Ien3IuIV2+fnlblu\nETEnab3tUUm7bf/jBfNLVzfbH5B0PCL2235P2jJlrFfVtRExbfvNku61/XTtzBLXa0mDdMQwLemK\nmueXV6f1ixdtXyZJ1d/He1yeltgeViUUvhIRu6qT+6Ju8yJiRtJ3VDlPVPa6XSPpV2w/q0r37HW2\n/1rlr5ciYrr6+7ik3ap0R5e+Xo0YpGB4RNJa21favkDSzZLu7nGZOuluSR+uPv6wpLt6WJaWuHJo\n8BeSnoqIP62Z1Q91W1U9UpDtEUnvk/S0Sl63iNgWEZdHxBpVPlMPRMRvq+T1sn2h7YvnH0u6QdLj\nKnm9GjVQF7jZ3qhKf+iQpDsi4rM9LlJLbN8p6T2q3OnxRUl/JGmPpK9LGlflzrO/HhELT1AXmu1r\nJf2dpIP6aX/1H6pynqHsdfsFVU5WDqnSIPt6RPyx7Tep5HWbV+1K+mREfKDs9bL9NlWOEqRKl/vf\nRMRny16vRg1UMAAAljZIXUkAgAYQDACABIIBAJBAMAAAEggGAEACwQAASCAYAAAJBAMAIOH/Ay+G\nbxNx2b7TAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13bfec780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression(C=77)\n",
    "logreg.fit(x, y)\n",
    "m=logreg.coef_\n",
    "plt.stem(m[0,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use kfold cross validation to find the optimal C:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nfold = 10\n",
    "kf = KFold(n_splits=nfold,shuffle=True)\n",
    "err_rate=np.zeros((20,nfold))\n",
    "C_test=np.logspace(-1,3,20)\n",
    "logreg = linear_model.LogisticRegression(penalty='l1',warm_start=True)\n",
    "\n",
    "for ifold, Ind in enumerate(kf.split(x)):   \n",
    "    Itr,Its=Ind\n",
    "    Xtr = x[Itr,:]\n",
    "    ytr = y[Itr]\n",
    "    Xts = x[Its,:]\n",
    "    yts = y[Its]\n",
    "    for ipen,c in enumerate(C_test):\n",
    "        logreg.C=c\n",
    "        logreg.fit(Xtr, ytr)\n",
    "        yhat = logreg.predict(Xts)\n",
    "        err_rate[ipen,ifold]=np.mean(yhat!=yts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum error rate is 0.073027 and SE is 0.003652\n"
     ]
    }
   ],
   "source": [
    "error_mean=np.mean(err_rate,axis=1)\n",
    "error_se=np.std(err_rate,axis=1)/np.sqrt(nfold-1)\n",
    "plt.errorbar(np.log10(C_test),error_mean,marker='o',yerr=error_se)\n",
    "imin=np.argmin(error_mean)\n",
    "print(\"The minimum error rate is %f and SE is %f\"%(error_mean[imin],error_se[imin]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected model order is 0.162378\n"
     ]
    }
   ],
   "source": [
    "err = error_mean[imin] + error_se[imin]\n",
    "iopt = np.where(error_mean < err)[0][0]\n",
    "C_opt = C_test[iopt]\n",
    "print(\"The selected model order is {0:f}\".format(C_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the optimal C and we get the the best coeffients diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13c29ed68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression(C=C_opt,penalty='l1')\n",
    "logreg.fit(x, y)\n",
    "W_l1=logreg.coef_\n",
    "plt.stem(W_l1[0,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Using Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the package we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "nh = 20\n",
    "nout = 1\n",
    "input_shape = (57,)\n",
    "model = Sequential()\n",
    "model.add(Dense(nh, input_shape=input_shape,activation='sigmoid',name='hidden'))\n",
    "model.add(Dense(nout,activation='sigmoid',name='output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden (Dense)               (None, 20)                1160      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,181\n",
      "Trainable params: 1,181\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xstrain = dataTrain[:, 0:57]\n",
    "Xstest = dataTest[:, 0:57]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model. Select the correct loss function, optimizer and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3500 samples, validate on 1100 samples\n",
      "Epoch 1/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.6629 - acc: 0.6023 - val_loss: 0.6210 - val_acc: 0.6791\n",
      "Epoch 2/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.6044 - acc: 0.6723 - val_loss: 0.5894 - val_acc: 0.6700\n",
      "Epoch 3/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.5739 - acc: 0.6774 - val_loss: 0.5649 - val_acc: 0.6809\n",
      "Epoch 4/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.5477 - acc: 0.6874 - val_loss: 0.5352 - val_acc: 0.6945\n",
      "Epoch 5/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.5183 - acc: 0.7074 - val_loss: 0.5041 - val_acc: 0.7200\n",
      "Epoch 6/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.4816 - acc: 0.7731 - val_loss: 0.4724 - val_acc: 0.7836\n",
      "Epoch 7/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.4428 - acc: 0.8094 - val_loss: 0.4327 - val_acc: 0.8073\n",
      "Epoch 8/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.4067 - acc: 0.8306 - val_loss: 0.4056 - val_acc: 0.8155\n",
      "Epoch 9/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.3731 - acc: 0.8551 - val_loss: 0.3748 - val_acc: 0.8573\n",
      "Epoch 10/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.3489 - acc: 0.8674 - val_loss: 0.3538 - val_acc: 0.8691\n",
      "Epoch 11/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.3294 - acc: 0.8791 - val_loss: 0.3305 - val_acc: 0.8764\n",
      "Epoch 12/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.3102 - acc: 0.8891 - val_loss: 0.3144 - val_acc: 0.8864\n",
      "Epoch 13/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.3005 - acc: 0.9000 - val_loss: 0.3051 - val_acc: 0.8864\n",
      "Epoch 14/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.2822 - acc: 0.9089 - val_loss: 0.3010 - val_acc: 0.9118\n",
      "Epoch 15/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.2700 - acc: 0.9160 - val_loss: 0.2814 - val_acc: 0.9055\n",
      "Epoch 16/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.2667 - acc: 0.9074 - val_loss: 0.2783 - val_acc: 0.9009\n",
      "Epoch 17/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.2560 - acc: 0.9146 - val_loss: 0.2630 - val_acc: 0.9100\n",
      "Epoch 18/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.2425 - acc: 0.9177 - val_loss: 0.2598 - val_acc: 0.9145\n",
      "Epoch 19/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.2363 - acc: 0.9226 - val_loss: 0.2509 - val_acc: 0.9045\n",
      "Epoch 20/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.2292 - acc: 0.9240 - val_loss: 0.2488 - val_acc: 0.8973\n",
      "Epoch 21/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.2257 - acc: 0.9266 - val_loss: 0.2381 - val_acc: 0.9055\n",
      "Epoch 22/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.2232 - acc: 0.9249 - val_loss: 0.2355 - val_acc: 0.9182\n",
      "Epoch 23/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.2119 - acc: 0.9303 - val_loss: 0.2291 - val_acc: 0.9191\n",
      "Epoch 24/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.2100 - acc: 0.9306 - val_loss: 0.2325 - val_acc: 0.9018\n",
      "Epoch 25/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.2106 - acc: 0.9306 - val_loss: 0.2261 - val_acc: 0.9109\n",
      "Epoch 26/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.2049 - acc: 0.9309 - val_loss: 0.2231 - val_acc: 0.9191\n",
      "Epoch 27/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.2017 - acc: 0.9311 - val_loss: 0.2251 - val_acc: 0.9209\n",
      "Epoch 28/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1992 - acc: 0.9340 - val_loss: 0.2191 - val_acc: 0.9191\n",
      "Epoch 29/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1950 - acc: 0.9354 - val_loss: 0.2156 - val_acc: 0.9209\n",
      "Epoch 30/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1910 - acc: 0.9389 - val_loss: 0.2180 - val_acc: 0.9218\n",
      "Epoch 31/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1875 - acc: 0.9357 - val_loss: 0.2196 - val_acc: 0.9182\n",
      "Epoch 32/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1845 - acc: 0.9363 - val_loss: 0.2065 - val_acc: 0.9200\n",
      "Epoch 33/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1842 - acc: 0.9380 - val_loss: 0.2124 - val_acc: 0.9227\n",
      "Epoch 34/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1883 - acc: 0.9363 - val_loss: 0.2134 - val_acc: 0.9245\n",
      "Epoch 35/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1826 - acc: 0.9386 - val_loss: 0.2020 - val_acc: 0.9236\n",
      "Epoch 36/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1776 - acc: 0.9389 - val_loss: 0.2066 - val_acc: 0.9145\n",
      "Epoch 37/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1986 - acc: 0.9294 - val_loss: 0.2107 - val_acc: 0.9182\n",
      "Epoch 38/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1808 - acc: 0.9357 - val_loss: 0.2062 - val_acc: 0.9264\n",
      "Epoch 39/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1759 - acc: 0.9400 - val_loss: 0.1983 - val_acc: 0.9227\n",
      "Epoch 40/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1782 - acc: 0.9380 - val_loss: 0.2132 - val_acc: 0.9245\n",
      "Epoch 41/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1731 - acc: 0.9414 - val_loss: 0.1953 - val_acc: 0.9309\n",
      "Epoch 42/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1756 - acc: 0.9380 - val_loss: 0.2069 - val_acc: 0.9264\n",
      "Epoch 43/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1753 - acc: 0.9403 - val_loss: 0.1907 - val_acc: 0.9255\n",
      "Epoch 44/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1709 - acc: 0.9394 - val_loss: 0.1970 - val_acc: 0.9264\n",
      "Epoch 45/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1679 - acc: 0.9411 - val_loss: 0.1929 - val_acc: 0.9300\n",
      "Epoch 46/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1677 - acc: 0.9431 - val_loss: 0.1876 - val_acc: 0.9273\n",
      "Epoch 47/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1651 - acc: 0.9420 - val_loss: 0.1884 - val_acc: 0.9291\n",
      "Epoch 48/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1654 - acc: 0.9437 - val_loss: 0.1872 - val_acc: 0.9300\n",
      "Epoch 49/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1627 - acc: 0.9434 - val_loss: 0.1855 - val_acc: 0.9309\n",
      "Epoch 50/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1650 - acc: 0.9429 - val_loss: 0.1900 - val_acc: 0.9264\n",
      "Epoch 51/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1668 - acc: 0.9426 - val_loss: 0.1841 - val_acc: 0.9327\n",
      "Epoch 52/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1617 - acc: 0.9446 - val_loss: 0.1859 - val_acc: 0.9291\n",
      "Epoch 53/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1616 - acc: 0.9434 - val_loss: 0.1844 - val_acc: 0.9327\n",
      "Epoch 54/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1667 - acc: 0.9403 - val_loss: 0.1894 - val_acc: 0.9300\n",
      "Epoch 55/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1642 - acc: 0.9437 - val_loss: 0.1860 - val_acc: 0.9291\n",
      "Epoch 56/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1570 - acc: 0.9469 - val_loss: 0.1792 - val_acc: 0.9318\n",
      "Epoch 57/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1591 - acc: 0.9429 - val_loss: 0.1929 - val_acc: 0.9273\n",
      "Epoch 58/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1567 - acc: 0.9449 - val_loss: 0.1808 - val_acc: 0.9300\n",
      "Epoch 59/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1587 - acc: 0.9463 - val_loss: 0.1784 - val_acc: 0.9300\n",
      "Epoch 60/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1547 - acc: 0.9480 - val_loss: 0.1803 - val_acc: 0.9309\n",
      "Epoch 61/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1514 - acc: 0.9477 - val_loss: 0.1796 - val_acc: 0.9318\n",
      "Epoch 62/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1533 - acc: 0.9474 - val_loss: 0.1778 - val_acc: 0.9327\n",
      "Epoch 63/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1518 - acc: 0.9477 - val_loss: 0.1778 - val_acc: 0.9327\n",
      "Epoch 64/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1577 - acc: 0.9466 - val_loss: 0.1846 - val_acc: 0.9318\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500/3500 [==============================] - 0s - loss: 0.1552 - acc: 0.9451 - val_loss: 0.1792 - val_acc: 0.9309\n",
      "Epoch 66/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1531 - acc: 0.9460 - val_loss: 0.1773 - val_acc: 0.9318\n",
      "Epoch 67/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1537 - acc: 0.9446 - val_loss: 0.1786 - val_acc: 0.9300\n",
      "Epoch 68/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1568 - acc: 0.9440 - val_loss: 0.1790 - val_acc: 0.9327\n",
      "Epoch 69/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1494 - acc: 0.9483 - val_loss: 0.1880 - val_acc: 0.9309\n",
      "Epoch 70/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1508 - acc: 0.9474 - val_loss: 0.1816 - val_acc: 0.9318\n",
      "Epoch 71/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1520 - acc: 0.9454 - val_loss: 0.1754 - val_acc: 0.9309\n",
      "Epoch 72/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1556 - acc: 0.9446 - val_loss: 0.1918 - val_acc: 0.9291\n",
      "Epoch 73/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1506 - acc: 0.9463 - val_loss: 0.1795 - val_acc: 0.9318\n",
      "Epoch 74/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1548 - acc: 0.9460 - val_loss: 0.1942 - val_acc: 0.9282\n",
      "Epoch 75/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1510 - acc: 0.9471 - val_loss: 0.1818 - val_acc: 0.9300\n",
      "Epoch 76/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1477 - acc: 0.9477 - val_loss: 0.1867 - val_acc: 0.9318\n",
      "Epoch 77/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1467 - acc: 0.9460 - val_loss: 0.1750 - val_acc: 0.9345\n",
      "Epoch 78/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1455 - acc: 0.9477 - val_loss: 0.1773 - val_acc: 0.9355\n",
      "Epoch 79/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1496 - acc: 0.9463 - val_loss: 0.1816 - val_acc: 0.9364\n",
      "Epoch 80/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1517 - acc: 0.9463 - val_loss: 0.1747 - val_acc: 0.9382\n",
      "Epoch 81/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1479 - acc: 0.9477 - val_loss: 0.1772 - val_acc: 0.9373\n",
      "Epoch 82/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1554 - acc: 0.9451 - val_loss: 0.1803 - val_acc: 0.9336\n",
      "Epoch 83/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1516 - acc: 0.9434 - val_loss: 0.1770 - val_acc: 0.9364\n",
      "Epoch 84/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1484 - acc: 0.9466 - val_loss: 0.1768 - val_acc: 0.9364\n",
      "Epoch 85/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1459 - acc: 0.9483 - val_loss: 0.1839 - val_acc: 0.9309\n",
      "Epoch 86/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1482 - acc: 0.9474 - val_loss: 0.1773 - val_acc: 0.9391\n",
      "Epoch 87/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1438 - acc: 0.9509 - val_loss: 0.1743 - val_acc: 0.9382\n",
      "Epoch 88/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1450 - acc: 0.9477 - val_loss: 0.1754 - val_acc: 0.9373\n",
      "Epoch 89/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1426 - acc: 0.9520 - val_loss: 0.1720 - val_acc: 0.9382\n",
      "Epoch 90/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1410 - acc: 0.9503 - val_loss: 0.1721 - val_acc: 0.9373\n",
      "Epoch 91/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1416 - acc: 0.9520 - val_loss: 0.1727 - val_acc: 0.9391\n",
      "Epoch 92/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1387 - acc: 0.9514 - val_loss: 0.1748 - val_acc: 0.9382\n",
      "Epoch 93/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1443 - acc: 0.9474 - val_loss: 0.1749 - val_acc: 0.9400\n",
      "Epoch 94/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1436 - acc: 0.9497 - val_loss: 0.1727 - val_acc: 0.9391\n",
      "Epoch 95/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1422 - acc: 0.9494 - val_loss: 0.1829 - val_acc: 0.9336\n",
      "Epoch 96/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1424 - acc: 0.9500 - val_loss: 0.1712 - val_acc: 0.9382\n",
      "Epoch 97/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1405 - acc: 0.9506 - val_loss: 0.1733 - val_acc: 0.9373\n",
      "Epoch 98/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1417 - acc: 0.9506 - val_loss: 0.1729 - val_acc: 0.9382\n",
      "Epoch 99/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1425 - acc: 0.9497 - val_loss: 0.1734 - val_acc: 0.9400\n",
      "Epoch 100/100\n",
      "3500/3500 [==============================] - 0s - loss: 0.1427 - acc: 0.9489 - val_loss: 0.1745 - val_acc: 0.9391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1333c8550>"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(Xstrain, ytrain, epochs=100, batch_size=100, validation_data=(Xstest,ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the predicted result of both train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized RSS training = 0.157740\n",
      "Normalized RSS test = 0.198617\n"
     ]
    }
   ],
   "source": [
    "y_tr_predicted = np.squeeze(model.predict(Xstrain))\n",
    "RSStrain = np.mean(((y_tr_predicted-ytrain)**2)/(np.std(ytrain)**2))\n",
    "print(\"Normalized RSS training = {0:f}\".format(RSStrain))\n",
    "y_ts_predicted = np.squeeze(model.predict(Xstest))\n",
    "RSStest = np.mean(((y_ts_predicted-ytest)**2)/(np.std(ytest)**2))\n",
    "print(\"Normalized RSS test = {0:f}\".format(RSStest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the result from the prediction of model is of format float, we have to convert it to binary number. We set the threshold of 0.5, and value greater than 0.5 can be seen as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of train set data is 0.952571\n",
      "Accuracy of test set data is 0.939091\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_tr_predicted)):\n",
    "    if y_tr_predicted[i] > 0.5:\n",
    "        y_tr_predicted[i] = 1\n",
    "    else :\n",
    "        y_tr_predicted[i] = 0\n",
    "for i in range(len(y_ts_predicted)):\n",
    "    if y_ts_predicted[i] > 0.5:\n",
    "        y_ts_predicted[i] = 1\n",
    "    else :\n",
    "        y_ts_predicted[i] = 0\n",
    "acctrain = np.mean(y_tr_predicted == ytrain)\n",
    "acctest = np.mean(y_ts_predicted == ytest)\n",
    "print(\"Accuracy of train set data is {0:f}\".format(acctrain))\n",
    "print(\"Accuracy of test set data is {0:f}\".format(acctest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take arbitratry 100 examples, scatter the true value and predicted value, from the graph below, blue spot means correctly matched, red spot means wrong prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x134c6b8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xaxis = np.linspace(1,100,100)\n",
    "plt.scatter(xaxis, ytest[200:300], color = 'r')\n",
    "plt.scatter(xaxis, y_ts_predicted[200:300], color = 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
